{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPT6qrfwGdb97h0DWEESzue",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanmay240405/disease-detection/blob/main/ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "TTnzbs0veCkI",
        "outputId": "302420c0-ff98-413a-95cb-cd88860ad398"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2411120d-1a68-4aeb-bb06-f9d582c905f2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2411120d-1a68-4aeb-bb06-f9d582c905f2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/paultimothymooney/breast-histopathology-images\n",
            "License(s): CC0-1.0\n",
            "Downloading breast-histopathology-images.zip to /content\n",
            " 99% 3.06G/3.10G [00:23<00:00, 219MB/s]\n",
            "100% 3.10G/3.10G [00:23<00:00, 141MB/s]\n",
            "10253  10301  12872  12930  13613  14305  16554  9041  9259\n",
            "10254  10302  12873  12931  13616  14306  16555  9043  9260\n",
            "10255  10303  12875  12932  13617  14321  16568  9044  9261\n",
            "10256  10304  12876  12933  13666  15471  16569  9073  9262\n",
            "10257  10305  12877  12934  13687  15472  16570  9075  9265\n",
            "10258  10306  12878  12935  13688  15473  16895  9076  9266\n",
            "10259  10307  12879  12947  13689  15510  16896  9077  9267\n",
            "10260  10308  12880  12948  13691  15512  8863\t 9078  9290\n",
            "10261  12241  12881  12949  13692  15513  8864\t 9081  9291\n",
            "10262  12242  12882  12951  13693  15514  8865\t 9083  9319\n",
            "10264  12626  12883  12954  13694  15515  8867\t 9123  9320\n",
            "10268  12748  12884  12955  13916  15516  8913\t 9124  9321\n",
            "10269  12749  12886  13018  14078  15632  8914\t 9125  9322\n",
            "10272  12750  12890  13019  14079  15633  8916\t 9126  9323\n",
            "10273  12751  12891  13020  14081  15634  8917\t 9135  9324\n",
            "10274  12752  12892  13021  14082  15839  8918\t 9173  9325\n",
            "10275  12810  12893  13022  14153  15840  8950\t 9174  9344\n",
            "10276  12811  12894  13023  14154  15902  8951\t 9175  9345\n",
            "10277  12817  12895  13024  14155  15903  8955\t 9176  9346\n",
            "10278  12818  12896  13025  14156  16014  8956\t 9177  9347\n",
            "10279  12819  12897  13106  14157  16085  8957\t 9178  9381\n",
            "10282  12820  12898  13400  14188  16165  8959\t 9181  9382\n",
            "10285  12821  12900  13401  14189  16166  8974\t 9225  9383\n",
            "10286  12822  12901  13402  14190  16167  8975\t 9226  IDC_regular_ps50_idx5\n",
            "10288  12823  12905  13403  14191  16531  8980\t 9227\n",
            "10290  12824  12906  13404  14192  16532  8984\t 9228\n",
            "10291  12826  12907  13458  14209  16533  9022\t 9250\n",
            "10292  12867  12908  13459  14210  16534  9023\t 9254\n",
            "10293  12868  12909  13460  14211  16550  9029\t 9255\n",
            "10295  12869  12910  13461  14212  16551  9035\t 9256\n",
            "10299  12870  12911  13462  14213  16552  9036\t 9257\n",
            "10300  12871  12929  13591  14304  16553  9037\t 9258\n"
          ]
        }
      ],
      "source": [
        "# Cell 1: Kaggle setup and dataset download\n",
        "from google.colab import files\n",
        "\n",
        "# Upload kaggle.json\n",
        "files.upload()\n",
        "\n",
        "# Setup Kaggle API credentials\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download Breast Histopathology Images dataset\n",
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images\n",
        "\n",
        "# Unzip into \"data\" folder\n",
        "!unzip -q breast-histopathology-images.zip -d data\n",
        "\n",
        "# Verify folder structure\n",
        "!ls data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "\n",
        "main_path = \"data\"\n",
        "\n",
        "class0_files = []\n",
        "class1_files = []\n",
        "\n",
        "for root, dirs, files in os.walk(main_path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".png\"):\n",
        "            if file.endswith(\"class0.png\"):\n",
        "                class0_files.append((os.path.join(root, file), 0))\n",
        "            else:\n",
        "                class1_files.append((os.path.join(root, file), 1))\n",
        "\n",
        "print(f\"Class 0: {len(class0_files)} images\")\n",
        "print(f\"Class 1: {len(class1_files)} images\")\n",
        "\n",
        "# Reduce number of images to avoid RAM issues\n",
        "sample_count = 40000  # change if needed\n",
        "class0_files = random.sample(class0_files, min(sample_count, len(class0_files)))\n",
        "class1_files = random.sample(class1_files, min(sample_count, len(class1_files)))\n",
        "\n",
        "# Combine and shuffle\n",
        "combine_data = class0_files + class1_files\n",
        "random.shuffle(combine_data)\n",
        "print(\"Total images after balancing:\", len(combine_data))\n",
        "\n",
        "# Train/Val split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_files, val_files = train_test_split(combine_data, test_size=0.2, random_state=42)\n",
        "print(f\"Train: {len(train_files)}, Validation: {len(val_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi6N66UkeIwJ",
        "outputId": "90e6ef5c-8615-4e54-b485-1c806b9df382"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0: 397476 images\n",
            "Class 1: 157572 images\n",
            "Total images after balancing: 80000\n",
            "Train: 64000, Validation: 16000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128,128)),  # same as your ViT patch size\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Dataset class\n",
        "class CancerDataset(Dataset):\n",
        "    def __init__(self, file_list, transform=None):\n",
        "        self.file_list = file_list\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.file_list[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Create Dataset objects\n",
        "train_dataset = CancerDataset(train_files, transform=transform)\n",
        "val_dataset = CancerDataset(val_files, transform=transform)\n",
        "\n",
        "# DataLoader\n",
        "batch_size = 2000  # change according to your GPU\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Number of training batches: {len(train_loader)}\")\n",
        "print(f\"Number of validation batches: {len(val_loader)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pu44CxIKfIg3",
        "outputId": "7ffab997-e7de-42eb-bf86-1274ae50565d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches: 32\n",
            "Number of validation batches: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "img_size = 128\n",
        "patch_size = 16\n",
        "num_channels = 3\n",
        "num_patches = (img_size // patch_size) ** 2\n",
        "num_heads = 1\n",
        "embed_dim = 128\n",
        "mlp_dim = 256\n",
        "transformer_units = 4\n",
        "\n",
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.patch_embed = nn.Conv2d(num_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "        x = x.flatten(2)\n",
        "        x = x.transpose(1,2)\n",
        "        return x\n",
        "\n",
        "class TransformerArchitecture(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer_norm_1 = nn.LayerNorm(embed_dim)\n",
        "        self.self_attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "        self.layer_norm_2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual_1 = x\n",
        "        attn_output = self.self_attention(self.layer_norm_1(x), self.layer_norm_1(x), self.layer_norm_1(x))[0]\n",
        "        x = attn_output + residual_1\n",
        "        residual_2 = x\n",
        "        x = self.mlp(self.layer_norm_2(x)) + residual_2\n",
        "        return x\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.patch_embedding = PatchEmbedding()\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1,embed_dim))\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))\n",
        "        self.transformer_layers = nn.Sequential(*[TransformerArchitecture() for _ in range(transformer_units)])\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, 2)  # 2 classes: tumor / no tumor\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)\n",
        "        B = x.size(0)\n",
        "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "        x = x + self.pos_embed\n",
        "        x = self.transformer_layers(x)\n",
        "        x = x[:,0]\n",
        "        x = self.mlp_head(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-1zWbHXOhKAv"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n"
      ],
      "metadata": {
        "id": "2z8tm35GhSjv"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = VisionTransformer().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_epoch = 0\n",
        "    total_epoch = 0\n",
        "    print(f\"\\nEpoch {epoch+1}\")\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct_epoch += (preds == labels).sum().item()\n",
        "        total_epoch += labels.size(0)\n",
        "\n",
        "        if batch_idx % 1 == 0:  # print every batch\n",
        "            batch_acc = 100.0 * (preds == labels).sum().item() / labels.size(0)\n",
        "            print(f\"  Batch {batch_idx+1}: Loss = {loss.item():.4f}, Accuracy = {batch_acc:.2f}%\")\n",
        "\n",
        "    epoch_acc = 100.0 * correct_epoch / total_epoch\n",
        "    print(f\"==> Epoch {epoch+1} Summary: Total Loss = {total_loss:.4f}, Accuracy = {epoch_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C3oRGmfhWt3",
        "outputId": "e39a95cc-6bd2-4b6c-86e0-bbbfa1539a5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1\n",
            "  Batch 1: Loss = 0.7565, Accuracy = 48.25%\n",
            "  Batch 2: Loss = 0.6883, Accuracy = 49.30%\n",
            "  Batch 3: Loss = 0.7101, Accuracy = 46.95%\n",
            "  Batch 4: Loss = 0.7006, Accuracy = 51.00%\n",
            "  Batch 5: Loss = 0.6939, Accuracy = 51.15%\n",
            "  Batch 6: Loss = 0.6928, Accuracy = 47.65%\n",
            "  Batch 7: Loss = 0.6760, Accuracy = 57.45%\n",
            "  Batch 8: Loss = 0.6786, Accuracy = 61.90%\n",
            "  Batch 9: Loss = 0.6781, Accuracy = 51.45%\n",
            "  Batch 10: Loss = 0.6832, Accuracy = 49.50%\n",
            "  Batch 11: Loss = 0.6802, Accuracy = 49.45%\n",
            "  Batch 12: Loss = 0.6707, Accuracy = 52.80%\n",
            "  Batch 13: Loss = 0.6673, Accuracy = 72.05%\n",
            "  Batch 14: Loss = 0.6616, Accuracy = 69.80%\n",
            "  Batch 15: Loss = 0.6632, Accuracy = 60.65%\n",
            "  Batch 16: Loss = 0.6658, Accuracy = 57.00%\n",
            "  Batch 17: Loss = 0.6599, Accuracy = 57.75%\n",
            "  Batch 18: Loss = 0.6597, Accuracy = 58.75%\n",
            "  Batch 19: Loss = 0.6532, Accuracy = 64.25%\n",
            "  Batch 20: Loss = 0.6478, Accuracy = 71.20%\n",
            "  Batch 21: Loss = 0.6464, Accuracy = 73.70%\n",
            "  Batch 22: Loss = 0.6444, Accuracy = 72.35%\n",
            "  Batch 23: Loss = 0.6412, Accuracy = 72.70%\n",
            "  Batch 24: Loss = 0.6408, Accuracy = 71.60%\n",
            "  Batch 25: Loss = 0.6302, Accuracy = 74.45%\n",
            "  Batch 26: Loss = 0.6300, Accuracy = 73.60%\n",
            "  Batch 27: Loss = 0.6265, Accuracy = 70.55%\n",
            "  Batch 28: Loss = 0.6245, Accuracy = 69.75%\n",
            "  Batch 29: Loss = 0.6197, Accuracy = 68.45%\n",
            "  Batch 30: Loss = 0.6150, Accuracy = 72.30%\n",
            "  Batch 31: Loss = 0.6157, Accuracy = 72.25%\n",
            "  Batch 32: Loss = 0.6122, Accuracy = 73.85%\n",
            "==> Epoch 1 Summary: Total Loss = 21.1341, Accuracy = 62.31%\n",
            "\n",
            "Epoch 2\n",
            "  Batch 1: Loss = 0.6099, Accuracy = 73.85%\n",
            "  Batch 2: Loss = 0.6024, Accuracy = 72.60%\n",
            "  Batch 3: Loss = 0.5968, Accuracy = 71.35%\n",
            "  Batch 4: Loss = 0.6047, Accuracy = 70.55%\n",
            "  Batch 5: Loss = 0.5863, Accuracy = 72.85%\n",
            "  Batch 6: Loss = 0.5971, Accuracy = 72.40%\n",
            "  Batch 7: Loss = 0.5862, Accuracy = 72.50%\n",
            "  Batch 8: Loss = 0.5715, Accuracy = 74.85%\n",
            "  Batch 9: Loss = 0.5615, Accuracy = 75.45%\n",
            "  Batch 10: Loss = 0.5667, Accuracy = 73.20%\n",
            "  Batch 11: Loss = 0.5668, Accuracy = 73.15%\n",
            "  Batch 12: Loss = 0.5566, Accuracy = 74.10%\n",
            "  Batch 13: Loss = 0.5485, Accuracy = 74.75%\n",
            "  Batch 14: Loss = 0.5457, Accuracy = 74.40%\n",
            "  Batch 15: Loss = 0.5547, Accuracy = 73.55%\n",
            "  Batch 16: Loss = 0.5450, Accuracy = 73.80%\n",
            "  Batch 17: Loss = 0.5412, Accuracy = 73.80%\n",
            "  Batch 18: Loss = 0.5425, Accuracy = 73.70%\n",
            "  Batch 19: Loss = 0.5655, Accuracy = 72.15%\n",
            "  Batch 20: Loss = 0.5456, Accuracy = 73.50%\n",
            "  Batch 21: Loss = 0.5324, Accuracy = 75.50%\n",
            "  Batch 22: Loss = 0.5520, Accuracy = 71.90%\n",
            "  Batch 23: Loss = 0.5385, Accuracy = 73.75%\n",
            "  Batch 24: Loss = 0.5301, Accuracy = 75.65%\n",
            "  Batch 25: Loss = 0.5681, Accuracy = 73.95%\n",
            "  Batch 26: Loss = 0.5236, Accuracy = 75.45%\n",
            "  Batch 27: Loss = 0.5623, Accuracy = 71.95%\n",
            "  Batch 28: Loss = 0.4938, Accuracy = 77.90%\n",
            "  Batch 29: Loss = 0.5352, Accuracy = 75.90%\n",
            "  Batch 30: Loss = 0.5236, Accuracy = 76.45%\n",
            "  Batch 31: Loss = 0.5367, Accuracy = 75.40%\n",
            "  Batch 32: Loss = 0.5361, Accuracy = 74.20%\n",
            "==> Epoch 2 Summary: Total Loss = 17.8276, Accuracy = 73.89%\n",
            "\n",
            "Epoch 3\n",
            "  Batch 1: Loss = 0.5368, Accuracy = 75.30%\n",
            "  Batch 2: Loss = 0.5372, Accuracy = 75.85%\n",
            "  Batch 3: Loss = 0.5306, Accuracy = 75.30%\n",
            "  Batch 4: Loss = 0.5245, Accuracy = 75.70%\n",
            "  Batch 5: Loss = 0.5334, Accuracy = 75.55%\n",
            "  Batch 6: Loss = 0.5149, Accuracy = 77.20%\n",
            "  Batch 7: Loss = 0.5371, Accuracy = 75.20%\n",
            "  Batch 8: Loss = 0.5141, Accuracy = 75.60%\n",
            "  Batch 9: Loss = 0.4989, Accuracy = 77.45%\n",
            "  Batch 10: Loss = 0.5195, Accuracy = 76.55%\n",
            "  Batch 11: Loss = 0.5126, Accuracy = 78.30%\n",
            "  Batch 12: Loss = 0.5117, Accuracy = 76.80%\n",
            "  Batch 13: Loss = 0.4965, Accuracy = 76.80%\n",
            "  Batch 14: Loss = 0.5042, Accuracy = 76.55%\n",
            "  Batch 15: Loss = 0.5231, Accuracy = 77.70%\n",
            "  Batch 16: Loss = 0.4952, Accuracy = 77.25%\n",
            "  Batch 17: Loss = 0.4878, Accuracy = 77.75%\n",
            "  Batch 18: Loss = 0.4984, Accuracy = 78.40%\n",
            "  Batch 19: Loss = 0.4820, Accuracy = 79.45%\n",
            "  Batch 20: Loss = 0.4963, Accuracy = 77.45%\n",
            "  Batch 21: Loss = 0.5010, Accuracy = 77.00%\n",
            "  Batch 22: Loss = 0.5025, Accuracy = 77.20%\n",
            "  Batch 23: Loss = 0.4951, Accuracy = 78.25%\n",
            "  Batch 24: Loss = 0.4883, Accuracy = 77.95%\n",
            "  Batch 25: Loss = 0.4904, Accuracy = 77.50%\n",
            "  Batch 26: Loss = 0.4749, Accuracy = 80.40%\n",
            "  Batch 27: Loss = 0.4919, Accuracy = 77.85%\n",
            "  Batch 28: Loss = 0.4653, Accuracy = 80.60%\n",
            "  Batch 29: Loss = 0.4805, Accuracy = 79.70%\n",
            "  Batch 30: Loss = 0.5069, Accuracy = 76.65%\n",
            "  Batch 31: Loss = 0.5258, Accuracy = 75.40%\n",
            "  Batch 32: Loss = 0.4954, Accuracy = 77.55%\n",
            "==> Epoch 3 Summary: Total Loss = 16.1726, Accuracy = 77.26%\n",
            "\n",
            "Epoch 4\n",
            "  Batch 1: Loss = 0.4758, Accuracy = 78.60%\n",
            "  Batch 2: Loss = 0.5152, Accuracy = 76.65%\n",
            "  Batch 3: Loss = 0.4921, Accuracy = 77.70%\n",
            "  Batch 4: Loss = 0.4819, Accuracy = 79.25%\n",
            "  Batch 5: Loss = 0.4761, Accuracy = 78.50%\n",
            "  Batch 6: Loss = 0.4966, Accuracy = 77.20%\n",
            "  Batch 7: Loss = 0.5115, Accuracy = 77.25%\n",
            "  Batch 8: Loss = 0.4906, Accuracy = 77.95%\n",
            "  Batch 9: Loss = 0.4613, Accuracy = 79.55%\n",
            "  Batch 10: Loss = 0.4613, Accuracy = 80.25%\n",
            "  Batch 11: Loss = 0.4711, Accuracy = 80.10%\n",
            "  Batch 12: Loss = 0.4849, Accuracy = 77.60%\n",
            "  Batch 13: Loss = 0.4832, Accuracy = 78.05%\n",
            "  Batch 14: Loss = 0.4812, Accuracy = 79.20%\n",
            "  Batch 15: Loss = 0.4643, Accuracy = 80.60%\n",
            "  Batch 16: Loss = 0.4797, Accuracy = 79.15%\n",
            "  Batch 17: Loss = 0.4818, Accuracy = 78.20%\n",
            "  Batch 18: Loss = 0.5120, Accuracy = 78.40%\n",
            "  Batch 19: Loss = 0.4747, Accuracy = 78.70%\n",
            "  Batch 20: Loss = 0.4828, Accuracy = 77.85%\n",
            "  Batch 21: Loss = 0.5267, Accuracy = 77.20%\n",
            "  Batch 22: Loss = 0.4756, Accuracy = 79.30%\n",
            "  Batch 23: Loss = 0.4662, Accuracy = 79.15%\n",
            "  Batch 24: Loss = 0.4491, Accuracy = 81.45%\n",
            "  Batch 25: Loss = 0.4752, Accuracy = 79.15%\n",
            "  Batch 26: Loss = 0.4722, Accuracy = 78.60%\n",
            "  Batch 27: Loss = 0.4777, Accuracy = 78.45%\n",
            "  Batch 28: Loss = 0.4744, Accuracy = 80.15%\n",
            "  Batch 29: Loss = 0.4828, Accuracy = 78.60%\n",
            "  Batch 30: Loss = 0.4856, Accuracy = 78.25%\n",
            "  Batch 31: Loss = 0.4729, Accuracy = 79.50%\n",
            "  Batch 32: Loss = 0.4853, Accuracy = 79.40%\n",
            "==> Epoch 4 Summary: Total Loss = 15.4219, Accuracy = 78.75%\n",
            "\n",
            "Epoch 5\n",
            "  Batch 1: Loss = 0.4737, Accuracy = 78.70%\n",
            "  Batch 2: Loss = 0.4963, Accuracy = 77.75%\n",
            "  Batch 3: Loss = 0.4736, Accuracy = 78.90%\n",
            "  Batch 4: Loss = 0.4999, Accuracy = 78.55%\n",
            "  Batch 5: Loss = 0.4644, Accuracy = 80.15%\n",
            "  Batch 6: Loss = 0.4710, Accuracy = 78.35%\n",
            "  Batch 7: Loss = 0.4748, Accuracy = 78.65%\n",
            "  Batch 8: Loss = 0.4886, Accuracy = 80.00%\n",
            "  Batch 9: Loss = 0.4511, Accuracy = 79.65%\n",
            "  Batch 10: Loss = 0.5140, Accuracy = 76.95%\n",
            "  Batch 11: Loss = 0.4782, Accuracy = 78.80%\n",
            "  Batch 12: Loss = 0.5006, Accuracy = 77.55%\n",
            "  Batch 13: Loss = 0.4828, Accuracy = 78.30%\n",
            "  Batch 14: Loss = 0.4837, Accuracy = 77.50%\n",
            "  Batch 15: Loss = 0.4768, Accuracy = 79.80%\n",
            "  Batch 16: Loss = 0.4973, Accuracy = 78.35%\n",
            "  Batch 17: Loss = 0.4489, Accuracy = 80.65%\n",
            "  Batch 18: Loss = 0.4777, Accuracy = 78.35%\n",
            "  Batch 19: Loss = 0.4664, Accuracy = 79.25%\n",
            "  Batch 20: Loss = 0.4909, Accuracy = 78.10%\n",
            "  Batch 21: Loss = 0.4441, Accuracy = 81.65%\n",
            "  Batch 22: Loss = 0.4423, Accuracy = 80.35%\n",
            "  Batch 23: Loss = 0.4652, Accuracy = 79.40%\n",
            "  Batch 24: Loss = 0.4790, Accuracy = 79.80%\n",
            "  Batch 25: Loss = 0.4605, Accuracy = 80.05%\n",
            "  Batch 26: Loss = 0.4645, Accuracy = 78.70%\n",
            "  Batch 27: Loss = 0.4373, Accuracy = 80.60%\n",
            "  Batch 28: Loss = 0.4667, Accuracy = 80.15%\n",
            "  Batch 29: Loss = 0.4573, Accuracy = 79.95%\n",
            "  Batch 30: Loss = 0.4733, Accuracy = 78.70%\n",
            "  Batch 31: Loss = 0.4666, Accuracy = 80.20%\n",
            "  Batch 32: Loss = 0.4581, Accuracy = 78.70%\n",
            "==> Epoch 5 Summary: Total Loss = 15.1255, Accuracy = 79.14%\n",
            "\n",
            "Epoch 6\n",
            "  Batch 1: Loss = 0.4587, Accuracy = 78.60%\n",
            "  Batch 2: Loss = 0.4510, Accuracy = 79.45%\n",
            "  Batch 3: Loss = 0.4738, Accuracy = 78.65%\n",
            "  Batch 4: Loss = 0.4610, Accuracy = 80.60%\n",
            "  Batch 5: Loss = 0.4638, Accuracy = 78.90%\n",
            "  Batch 6: Loss = 0.4854, Accuracy = 78.25%\n",
            "  Batch 7: Loss = 0.4735, Accuracy = 79.15%\n",
            "  Batch 8: Loss = 0.4558, Accuracy = 79.95%\n",
            "  Batch 9: Loss = 0.4911, Accuracy = 78.85%\n",
            "  Batch 10: Loss = 0.4626, Accuracy = 79.60%\n",
            "  Batch 11: Loss = 0.4838, Accuracy = 77.05%\n",
            "  Batch 12: Loss = 0.4569, Accuracy = 79.35%\n",
            "  Batch 13: Loss = 0.4802, Accuracy = 78.00%\n",
            "  Batch 14: Loss = 0.4500, Accuracy = 79.85%\n",
            "  Batch 15: Loss = 0.4769, Accuracy = 80.05%\n",
            "  Batch 16: Loss = 0.4654, Accuracy = 79.20%\n",
            "  Batch 17: Loss = 0.4657, Accuracy = 79.55%\n",
            "  Batch 18: Loss = 0.4612, Accuracy = 79.20%\n",
            "  Batch 19: Loss = 0.4624, Accuracy = 80.50%\n",
            "  Batch 20: Loss = 0.4552, Accuracy = 79.95%\n",
            "  Batch 21: Loss = 0.4546, Accuracy = 80.60%\n",
            "  Batch 22: Loss = 0.4605, Accuracy = 79.65%\n",
            "  Batch 23: Loss = 0.4598, Accuracy = 79.95%\n",
            "  Batch 24: Loss = 0.4456, Accuracy = 80.40%\n",
            "  Batch 25: Loss = 0.4437, Accuracy = 80.95%\n",
            "  Batch 26: Loss = 0.4640, Accuracy = 79.85%\n",
            "  Batch 27: Loss = 0.4567, Accuracy = 79.20%\n",
            "  Batch 28: Loss = 0.4471, Accuracy = 79.85%\n",
            "  Batch 29: Loss = 0.4658, Accuracy = 78.90%\n",
            "  Batch 30: Loss = 0.4594, Accuracy = 79.10%\n",
            "  Batch 31: Loss = 0.4539, Accuracy = 80.10%\n",
            "  Batch 32: Loss = 0.4399, Accuracy = 80.85%\n",
            "==> Epoch 6 Summary: Total Loss = 14.7854, Accuracy = 79.50%\n",
            "\n",
            "Epoch 7\n",
            "  Batch 1: Loss = 0.4625, Accuracy = 78.80%\n",
            "  Batch 2: Loss = 0.4372, Accuracy = 81.05%\n",
            "  Batch 3: Loss = 0.4715, Accuracy = 79.25%\n",
            "  Batch 4: Loss = 0.4454, Accuracy = 80.70%\n",
            "  Batch 5: Loss = 0.4546, Accuracy = 80.75%\n",
            "  Batch 6: Loss = 0.4642, Accuracy = 78.80%\n",
            "  Batch 7: Loss = 0.4614, Accuracy = 79.40%\n",
            "  Batch 8: Loss = 0.4696, Accuracy = 79.15%\n",
            "  Batch 9: Loss = 0.4320, Accuracy = 80.55%\n",
            "  Batch 10: Loss = 0.4890, Accuracy = 76.75%\n",
            "  Batch 11: Loss = 0.4552, Accuracy = 79.00%\n",
            "  Batch 12: Loss = 0.4477, Accuracy = 81.10%\n",
            "  Batch 13: Loss = 0.4896, Accuracy = 77.20%\n",
            "  Batch 14: Loss = 0.4385, Accuracy = 80.05%\n",
            "  Batch 15: Loss = 0.4548, Accuracy = 79.75%\n",
            "  Batch 16: Loss = 0.4658, Accuracy = 79.20%\n",
            "  Batch 17: Loss = 0.4457, Accuracy = 80.50%\n",
            "  Batch 18: Loss = 0.4441, Accuracy = 80.15%\n",
            "  Batch 19: Loss = 0.4531, Accuracy = 79.90%\n",
            "  Batch 20: Loss = 0.4673, Accuracy = 78.85%\n",
            "  Batch 21: Loss = 0.4622, Accuracy = 79.85%\n",
            "  Batch 22: Loss = 0.4453, Accuracy = 80.55%\n",
            "  Batch 23: Loss = 0.4703, Accuracy = 79.80%\n",
            "  Batch 24: Loss = 0.4643, Accuracy = 79.75%\n",
            "  Batch 25: Loss = 0.4375, Accuracy = 81.35%\n",
            "  Batch 26: Loss = 0.4408, Accuracy = 80.00%\n",
            "  Batch 27: Loss = 0.4640, Accuracy = 79.10%\n",
            "  Batch 28: Loss = 0.4577, Accuracy = 78.15%\n",
            "  Batch 29: Loss = 0.4658, Accuracy = 79.00%\n",
            "  Batch 30: Loss = 0.4365, Accuracy = 81.40%\n",
            "  Batch 31: Loss = 0.4364, Accuracy = 82.00%\n",
            "  Batch 32: Loss = 0.4622, Accuracy = 80.00%\n",
            "==> Epoch 7 Summary: Total Loss = 14.5924, Accuracy = 79.75%\n",
            "\n",
            "Epoch 8\n",
            "  Batch 1: Loss = 0.4351, Accuracy = 80.95%\n",
            "  Batch 2: Loss = 0.4583, Accuracy = 80.25%\n",
            "  Batch 3: Loss = 0.4484, Accuracy = 79.85%\n",
            "  Batch 4: Loss = 0.4509, Accuracy = 79.30%\n",
            "  Batch 5: Loss = 0.4505, Accuracy = 80.70%\n",
            "  Batch 6: Loss = 0.4432, Accuracy = 80.85%\n",
            "  Batch 7: Loss = 0.4554, Accuracy = 79.10%\n",
            "  Batch 8: Loss = 0.4678, Accuracy = 79.05%\n",
            "  Batch 9: Loss = 0.4418, Accuracy = 80.70%\n",
            "  Batch 10: Loss = 0.4689, Accuracy = 78.95%\n",
            "  Batch 11: Loss = 0.4299, Accuracy = 81.45%\n",
            "  Batch 12: Loss = 0.4309, Accuracy = 81.40%\n",
            "  Batch 13: Loss = 0.4438, Accuracy = 81.10%\n",
            "  Batch 14: Loss = 0.4395, Accuracy = 81.20%\n",
            "  Batch 15: Loss = 0.4479, Accuracy = 80.55%\n",
            "  Batch 16: Loss = 0.4559, Accuracy = 80.00%\n",
            "  Batch 17: Loss = 0.4586, Accuracy = 79.95%\n",
            "  Batch 18: Loss = 0.4289, Accuracy = 80.30%\n",
            "  Batch 19: Loss = 0.4427, Accuracy = 80.05%\n",
            "  Batch 20: Loss = 0.4574, Accuracy = 79.60%\n",
            "  Batch 21: Loss = 0.4597, Accuracy = 79.20%\n",
            "  Batch 22: Loss = 0.4594, Accuracy = 80.10%\n",
            "  Batch 23: Loss = 0.4464, Accuracy = 79.25%\n",
            "  Batch 24: Loss = 0.4486, Accuracy = 80.45%\n",
            "  Batch 25: Loss = 0.4460, Accuracy = 79.30%\n",
            "  Batch 26: Loss = 0.4499, Accuracy = 80.35%\n",
            "  Batch 27: Loss = 0.4555, Accuracy = 79.80%\n",
            "  Batch 28: Loss = 0.4362, Accuracy = 80.35%\n",
            "  Batch 29: Loss = 0.4398, Accuracy = 80.50%\n",
            "  Batch 30: Loss = 0.4413, Accuracy = 80.00%\n",
            "  Batch 31: Loss = 0.4514, Accuracy = 80.00%\n",
            "  Batch 32: Loss = 0.4468, Accuracy = 79.65%\n",
            "==> Epoch 8 Summary: Total Loss = 14.3369, Accuracy = 80.13%\n",
            "\n",
            "Epoch 9\n",
            "  Batch 1: Loss = 0.4668, Accuracy = 79.20%\n",
            "  Batch 2: Loss = 0.4405, Accuracy = 81.10%\n",
            "  Batch 3: Loss = 0.4606, Accuracy = 79.60%\n",
            "  Batch 4: Loss = 0.4570, Accuracy = 79.45%\n",
            "  Batch 5: Loss = 0.4750, Accuracy = 78.35%\n",
            "  Batch 6: Loss = 0.4397, Accuracy = 80.75%\n",
            "  Batch 7: Loss = 0.4755, Accuracy = 77.40%\n",
            "  Batch 8: Loss = 0.4373, Accuracy = 81.45%\n",
            "  Batch 9: Loss = 0.4648, Accuracy = 80.50%\n",
            "  Batch 10: Loss = 0.4612, Accuracy = 80.00%\n",
            "  Batch 11: Loss = 0.4699, Accuracy = 78.60%\n",
            "  Batch 12: Loss = 0.4546, Accuracy = 79.80%\n",
            "  Batch 13: Loss = 0.4529, Accuracy = 79.40%\n",
            "  Batch 14: Loss = 0.4516, Accuracy = 79.75%\n",
            "  Batch 15: Loss = 0.4514, Accuracy = 80.00%\n",
            "  Batch 16: Loss = 0.4380, Accuracy = 79.80%\n",
            "  Batch 17: Loss = 0.4395, Accuracy = 80.70%\n",
            "  Batch 18: Loss = 0.4551, Accuracy = 79.25%\n",
            "  Batch 19: Loss = 0.4328, Accuracy = 80.20%\n",
            "  Batch 20: Loss = 0.4494, Accuracy = 79.70%\n",
            "  Batch 21: Loss = 0.4353, Accuracy = 79.95%\n",
            "  Batch 22: Loss = 0.4447, Accuracy = 79.90%\n",
            "  Batch 23: Loss = 0.4217, Accuracy = 81.50%\n",
            "  Batch 24: Loss = 0.4530, Accuracy = 80.10%\n",
            "  Batch 25: Loss = 0.4849, Accuracy = 77.65%\n",
            "  Batch 26: Loss = 0.4338, Accuracy = 80.40%\n",
            "  Batch 27: Loss = 0.4425, Accuracy = 81.35%\n",
            "  Batch 28: Loss = 0.4574, Accuracy = 79.95%\n",
            "  Batch 29: Loss = 0.4500, Accuracy = 79.70%\n",
            "  Batch 30: Loss = 0.4337, Accuracy = 81.10%\n",
            "  Batch 31: Loss = 0.4134, Accuracy = 83.05%\n",
            "  Batch 32: Loss = 0.4391, Accuracy = 81.00%\n",
            "==> Epoch 9 Summary: Total Loss = 14.3834, Accuracy = 80.02%\n",
            "\n",
            "Epoch 10\n",
            "  Batch 1: Loss = 0.4676, Accuracy = 78.60%\n",
            "  Batch 2: Loss = 0.4606, Accuracy = 79.50%\n",
            "  Batch 3: Loss = 0.4257, Accuracy = 82.10%\n",
            "  Batch 4: Loss = 0.4465, Accuracy = 80.20%\n",
            "  Batch 5: Loss = 0.4280, Accuracy = 81.25%\n",
            "  Batch 6: Loss = 0.4169, Accuracy = 81.10%\n",
            "  Batch 7: Loss = 0.4365, Accuracy = 81.95%\n",
            "  Batch 8: Loss = 0.4457, Accuracy = 79.65%\n",
            "  Batch 9: Loss = 0.4469, Accuracy = 80.80%\n",
            "  Batch 10: Loss = 0.4678, Accuracy = 79.70%\n",
            "  Batch 11: Loss = 0.4506, Accuracy = 80.25%\n",
            "  Batch 12: Loss = 0.4396, Accuracy = 80.40%\n",
            "  Batch 13: Loss = 0.4594, Accuracy = 79.45%\n",
            "  Batch 14: Loss = 0.4332, Accuracy = 80.90%\n",
            "  Batch 15: Loss = 0.4431, Accuracy = 79.70%\n",
            "  Batch 16: Loss = 0.4326, Accuracy = 81.45%\n",
            "  Batch 17: Loss = 0.4502, Accuracy = 79.80%\n",
            "  Batch 18: Loss = 0.4463, Accuracy = 80.20%\n",
            "  Batch 19: Loss = 0.4673, Accuracy = 78.30%\n",
            "  Batch 20: Loss = 0.4638, Accuracy = 79.40%\n",
            "  Batch 21: Loss = 0.4499, Accuracy = 80.45%\n",
            "  Batch 22: Loss = 0.4390, Accuracy = 80.10%\n",
            "  Batch 23: Loss = 0.4542, Accuracy = 79.15%\n",
            "  Batch 24: Loss = 0.4416, Accuracy = 80.45%\n",
            "  Batch 25: Loss = 0.4310, Accuracy = 80.50%\n",
            "  Batch 26: Loss = 0.4349, Accuracy = 81.15%\n",
            "  Batch 27: Loss = 0.4354, Accuracy = 80.80%\n",
            "  Batch 28: Loss = 0.4619, Accuracy = 78.65%\n",
            "  Batch 29: Loss = 0.4425, Accuracy = 80.30%\n",
            "  Batch 30: Loss = 0.4372, Accuracy = 81.15%\n",
            "  Batch 31: Loss = 0.4592, Accuracy = 79.40%\n",
            "  Batch 32: Loss = 0.4743, Accuracy = 77.60%\n",
            "==> Epoch 10 Summary: Total Loss = 14.2894, Accuracy = 80.14%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "val_acc = 100 * correct / total\n",
        "print(f\"Validation Accuracy: {val_acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YRSPV1IhZGK",
        "outputId": "cd21bd44-5ab9-40fc-81dc-eb6c83ca7044"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 79.76%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VltEpMpRpo6F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}